import argparse

import onnxruntime


def check_onnx_tensor(model_path):
    # ì„¸ì…˜ ìƒì„±
    session = onnxruntime.InferenceSession(model_path, providers=["CPUExecutionProvider"])

    # ì…ë ¥ ì •ë³´ í™•ì¸
    print("ğŸ”¹ Inputs:")
    for input_tensor in session.get_inputs():
        print(f"  name: {input_tensor.name}")
        print(f"  shape: {input_tensor.shape}")
        print(f"  type: {input_tensor.type}")

    # ì¶œë ¥ ì •ë³´ í™•ì¸
    print("\nğŸ”¹ Outputs:")
    for output_tensor in session.get_outputs():
        print(f"  name: {output_tensor.name}")
        print(f"  shape: {output_tensor.shape}")
        print(f"  type: {output_tensor.type}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ONNX ëª¨ë¸ì˜ ì…ë ¥/ì¶œë ¥ í…ì„œ ì •ë³´ í™•ì¸")
    parser.add_argument("--model_path", type=str, default="yolo11n.onnx", help="ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
    args = parser.parse_args()
    check_onnx_tensor(args.model_path)
